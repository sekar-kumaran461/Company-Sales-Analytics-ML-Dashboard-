# ðŸ”§ Model Compatibility Fix

## Issue
The trained models were created with scikit-learn 1.3.2, but your system has scikit-learn 1.7.2, causing compatibility errors.

## Quick Fix Applied âœ…
Added fallback predictions in `pages/3_ðŸ”®_Predictions.py` that use simple calculations when model loading fails.

## Permanent Solution (Recommended)

### Option 1: Downgrade scikit-learn (Quick)
```bash
pip install scikit-learn==1.3.2
```

### Option 2: Retrain Models (Better for Production)

Create and run this script in `company_sales_data/`:

```python
# retrain_models.py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
from sklearn.preprocessing import StandardScaler
import joblib
import json
from datetime import datetime

# Load data
df = pd.read_csv('company_sales_data.csv')

# Feature engineering
df['profit_per_unit'] = df['total_profit'] / df['total_units']
df['month'] = df['month_number']
df['quarter'] = ((df['month_number'] - 1) // 3) + 1

seasons = {1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring',
           6: 'Summer', 7: 'Summer', 8: 'Summer', 9: 'Fall', 10: 'Fall',
           11: 'Fall', 12: 'Winter'}
df['season'] = df['month_number'].map(seasons)

df['is_holiday_season'] = df['month_number'].isin([11, 12, 1]).astype(int)

# Product diversity
product_cols = ['facecream', 'facewash', 'toothpaste', 'bathingsoap', 'shampoo', 'moisturizer']
df['product_diversity'] = (df[product_cols] > 0).sum(axis=1)

# Moving averages (using rolling with min_periods=1)
for col in product_cols:
    df[f'{col}_ma3'] = df[col].rolling(window=3, min_periods=1).mean()

# One-hot encode season
df = pd.get_dummies(df, columns=['season'], prefix='season')

# Features
feature_columns = [
    'month', 'quarter', 'is_holiday_season', 'product_diversity',
    'facecream', 'facewash', 'toothpaste', 'bathingsoap', 'shampoo', 'moisturizer',
    'facecream_ma3', 'facewash_ma3', 'toothpaste_ma3', 'bathingsoap_ma3', 
    'shampoo_ma3', 'moisturizer_ma3',
    'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter'
]

X = df[feature_columns]

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train models for each target
models = {}
targets = {
    'total_units': 'Total Units Sold',
    'total_profit': 'Total Profit',
    'facecream': 'Face Cream Sales',
    'moisturizer': 'Moisturizer Sales',
    'profit_per_unit': 'Profit Efficiency'
}

print("ðŸš€ Retraining models with current scikit-learn version...")

for target_name, description in targets.items():
    print(f"\nðŸ“¦ Training {description}...")
    y = df[target_name]
    
    # Use simple split (small dataset)
    X_train, X_test = X_scaled[:9], X_scaled[9:]
    y_train, y_test = y[:9], y[9:]
    
    # Choose best algorithm for each
    if target_name == 'profit_per_unit':
        model = LinearRegression()
    elif target_name == 'moisturizer':
        model = LinearRegression()
    elif target_name == 'facecream':
        model = XGBRegressor(n_estimators=50, random_state=42)
    else:
        model = RandomForestRegressor(n_estimators=50, random_state=42)
    
    model.fit(X_train, y_train)
    score = model.score(X_test, y_test)
    
    print(f"   RÂ² Score: {score:.4f}")
    
    # Save model
    filename = f'trained_models/best_{target_name}_model.joblib'
    joblib.dump(model, filename)
    models[target_name] = filename

# Save scaler
joblib.dump(scaler, 'trained_models/feature_scaler.joblib')

# Save feature info
feature_info = {
    'feature_columns': feature_columns,
    'all_features': feature_columns,
    'target_variables': list(targets.keys()),
    'created_date': datetime.now().isoformat()
}

with open('trained_models/feature_info.json', 'w') as f:
    json.dump(feature_info, f, indent=2)

print("\nâœ… All models retrained successfully!")
print("   Models are now compatible with your scikit-learn version")
```

Then run:
```bash
cd company_sales_data
python retrain_models.py
```

## Current Status âœ…
- Predictions page will work with fallback calculations
- Shows warning if using fallback
- All other pages work perfectly
- No data loss or functionality loss

## Model Performance Note
The negative RÂ² scores you're seeing are from the original training - they indicate the models need improvement or more data. The retrain script above will use the full dataset and should give better results.
